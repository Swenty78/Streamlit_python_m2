
# ğŸ—‚ï¸ Coworking Data Pipeline - Ãle-de-France

Ce projet permet de **scraper, nettoyer, gÃ©olocaliser et visualiser** les espaces de coworking en Ãle-de-France Ã  partir du site source jusquâ€™Ã  un fichier CSV final exploitable dans une application Streamlit.

---

## ğŸ“¦ PrÃ©requis

Avant dâ€™exÃ©cuter ce pipeline, installe les dÃ©pendances nÃ©cessaires :

```bash
pip install -r requirements.txt
```

### ğŸ“ Structure recommandÃ©e

```
.
â”œâ”€â”€ extract.py                # Scraping initial du site source
â”œâ”€â”€ data_cleaning.py         # Nettoyage du fichier brut
â”œâ”€â”€ geo_location.py          # Ajout des coordonnÃ©es gÃ©ographiques
â”œâ”€â”€ data_cleaning_geo.py     # Nettoyage final et formatage
â”œâ”€â”€ fichier_nettoye_geo.csv  # ğŸ”¥ Fichier final exploitable
â”œâ”€â”€ app.py                   # Application Streamlit
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ Ã‰tapes du traitement

### 1. ğŸ” `extract.py`

> **But :** Scraper les donnÃ©es d'espaces de coworking (nom, adresse, etc.)

- RÃ©cupÃ¨re les informations depuis un site web ou une API
- GÃ©nÃ¨re un fichier brut `raw_data.csv` ou Ã©quivalent
- âš ï¸ Peut nÃ©cessiter un `User-Agent` et un `time.sleep()` pour Ã©viter les blocages

```bash
python extract.py
```

---

### 2. ğŸ§¼ `data_cleaning.py`

> **But :** Nettoyer les chaÃ®nes de caractÃ¨res, les accents, les doublons, les espaces, etc.

- Normalise les textes (accents, majuscules/minuscules)
- Supprime ou remplace les valeurs manquantes
- Ã‰crit un fichier propre `clean_data.csv`

```bash
python data_cleaning.py
```

---

### 3. ğŸŒ `geo_location.py`

> **But :** Ajouter les colonnes `latitude` et `longitude` via l'API `Nominatim` de `geopy`.

- Boucle sur chaque adresse
- Appelle lâ€™API de gÃ©ocodage pour remplir les coordonnÃ©es
- Ajoute deux nouvelles colonnes au CSV

```bash
python geo_location.py
```

**Remarques :**
- Nominatim impose une limite de **1 requÃªte par seconde**
- En cas de timeouts, le script inclut une logique de retry

---

### 4. ğŸ§½ `data_cleaning_geo.py`

> **But :** Nettoyage final, suppression des lignes incomplÃ¨tes, rÃ©organisation des colonnes

- Supprime les entrÃ©es sans gÃ©olocalisation
- Formate proprement les champs pour l'affichage
- Produit le fichier final : `fichier_nettoye_geo.csv`

```bash
python data_cleaning_geo.py
```

---

## âœ… Fichier final

> **ğŸ“„ `fichier_nettoye_geo.csv`**

Ce fichier contient toutes les donnÃ©es prÃªtes Ã  l'emploi, notamment :

- `nom`, `adresse`, `tÃ©lÃ©phone`, `AccÃ¨s`, `Site`, `Instagram`
- `latitude`, `longitude` â†’ obtenues par gÃ©ocodage
- Utilisable directement dans l'application Streamlit `app.py`

---

## ğŸ–¥ï¸ Utilisation dans Streamlit

```bash
streamlit run app.py
```

Cette application affiche :
- Une carte interactive Folium
- Des statistiques par arrondissement
- Une prÃ©sence web (Instagram, site)
- Une liste des espaces de coworking

---

## ğŸ” Bonnes pratiques

- Ne pas abuser de l'API de gÃ©ocodage (limite de Nominatim)
- Conserver les CSV intermÃ©diaires pour audit/debug
- Documenter les champs crÃ©Ã©s ou transformÃ©s dans chaque Ã©tape
- Ajouter des logs si les scripts doivent tourner en prod

---

## ğŸ“Œ TODO possibles

- Ajouter un export GeoJSON pour intÃ©gration SIG
- CrÃ©er une base de donnÃ©es SQLite ou PostgreSQL pour requÃªtes complexes
- Rendre le scraping plus robuste avec `requests + BeautifulSoup` ou `Selenium`


---
## ğŸ¯ Objectif

Ce projet a pour but de fournir un **exemple complet et concret de pipeline de traitement de donnÃ©es** intÃ©grant :

- Le **scraping** d'informations depuis un site web,
- Le **nettoyage et la structuration** de la donnÃ©e avec `pandas`,
- Lâ€™**enrichissement par gÃ©ocodage** des adresses via lâ€™API `Nominatim` de `geopy`,
- Et la crÃ©ation dâ€™une **mini-application web interactive** avec `Streamlit`.

Le tout est conÃ§u pour dÃ©montrer comment transformer une **donnÃ©e brute non exploitable** en un **produit interactif visualisable** : carte interactive, statistiques dynamiques, filtres, liens Google Maps, etc.

Ce projet est idÃ©al comme **cas dâ€™usage pÃ©dagogique ou dÃ©monstratif** pour :

- Lâ€™analyse de donnÃ©es gÃ©ographiques,
- Lâ€™automatisation de workflows de donnÃ©es,
- La crÃ©ation rapide de dashboard lÃ©ger sans backend.

---

## ğŸ‘¨â€ğŸ’» Auteur

Projet rÃ©alisÃ© par Capgras NoÃ©, dans le cadre de cours de pyton de M2.
